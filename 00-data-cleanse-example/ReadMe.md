# Identify and Remove Duplicate Records
## Utilize the Pandas library to find and remove duplicate records from a CSV file

---
These scripts identify duplicate records and create a "clean" file where duplicates are removed.

1. Navigate to 01-data-cleanse-example/duplicates_find.ipynb in repository and run
    * creates a CSV file from the input file containing only the duplicate records
2. Run duplicates_remove.ipynb from same directory
    * removes the duplicate records from the input file using CSV module and Pandas

Input and output files are found in Resources

## OBJECTIVE

* Emphasize importance of understanding and cleansing data
### Talking Points

* Why bother examining duplicates?
* How could this process be automated? 
* What is the importance of data cleansing?

### TO DO

* Make process more object oriented with conditional on the ```python pd.concat``` object.

### CAUTION

Content was downloaded previously and is not to be taken as accurate or current. Users can download a data update prior to running scripts.
* DATA SOURCE: https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-2018-to-Present/wg3w-h783
